{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsXo+C7JPrRmcKYCbMx/0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianiu/Prognosemodell_Online_Kreditzahlungsverkehr/blob/main/models/test/model_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Daten Laden"
      ],
      "metadata": {
        "id": "3garWEz2sR9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotheken laden\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://github.com/sebastianiu/Prognosemodell_Online_Kreditzahlungsverkehr/raw/main/data/raw/PSP_Jan_Feb_2019.xlsx\"\n",
        "Datensatz = pd.read_excel(url)\n",
        "Datensatz = Datensatz.rename(columns = {\"Unnamed: 0\":\"id\"})"
      ],
      "metadata": {
        "id": "DeUdReV4UF31"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "607cnRvOUFgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Datenaufbereitung"
      ],
      "metadata": {
        "id": "005GLg72O2F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilbiotheken laden\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Datenaufbereitung\n",
        "label_encoder_PSP = LabelEncoder()\n",
        "label_encoder_country = LabelEncoder()\n",
        "label_encoder_card = LabelEncoder()\n",
        "label_encoder_weekday = LabelEncoder()\n",
        "\n",
        "ML_Daten = Datensatz.filter(['amount','success','PSP','country','card','tmsp','3D_secured'], axis=1)\n",
        "\n",
        "ML_Daten['country'] = label_encoder_country.fit_transform(ML_Daten['country'])\n",
        "ML_Daten['PSP'] = label_encoder_PSP.fit_transform(ML_Daten['PSP'])\n",
        "ML_Daten['card'] = label_encoder_card.fit_transform(ML_Daten['card'])\n",
        "\n",
        "# Datumswerte in Tag/ Wochentag/ Stunde aufteilen\n",
        "ML_Daten['weekday'] = ML_Daten['tmsp'].dt.day_name()\n",
        "ML_Daten['weekday'] = label_encoder_weekday.fit_transform(ML_Daten['weekday'])\n",
        "ML_Daten['day'] = ML_Daten['tmsp'].dt.strftime('%d').astype(int)\n",
        "ML_Daten['hour'] = ML_Daten['tmsp'].dt.strftime('%H').astype(int)\n",
        "\n",
        "# Separation in X Merkmale and Zielvariable Y\n",
        "Y = ML_Daten['success']\n",
        "X = ML_Daten.filter(['amount','PSP','3D_secured','card','country','weekday','day','hour'], axis=1)\n",
        "\n",
        "# Aufteilung in Trainings- und Validierungsdatensatz\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "3Fyc9fhFDYv-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Bewertungsfunktionen"
      ],
      "metadata": {
        "id": "K472PFtoDQrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import  roc_curve,auc,accuracy_score, f1_score\n",
        "\n",
        "def Visualisierung_AUC(model,x_test,y_test):\n",
        "  # Berechnung der Falsch-Positiv-Rate und der Wahr-Positiv-Rate für alle Schwellenwerte der Klassifizierung\n",
        "  probs = model.predict_proba(x_test)\n",
        "  preds = probs[:,1]\n",
        "  fpr, tpr, threshold = roc_curve(y_test, preds)\n",
        "  auc_value = round(auc(fpr,tpr),2)\n",
        "  df = pd.DataFrame(np.column_stack([fpr, tpr, threshold]), columns=['FPR', 'TPR', 'Threshold'])\n",
        "  # Visualisierung\n",
        "  fig = px.line(df, x='FPR', y=\"TPR\",title = f'AUC-Wert = {auc_value}')\n",
        "  fig.update_layout(shapes = [{'type': 'line', 'yref': 'paper', 'xref': 'paper', 'y0': 0, 'y1': 1, 'x0': 0, 'x1': 1,'line_color':'red','line_dash':'dot'}])\n",
        "  fig.show()\n",
        "\n",
        "def Visualisierung_Class_Errors(model,x_test,y_test):\n",
        "  #Vorhersage\n",
        "  y_pred = model.predict(x_test)\n",
        "  #Zippe Daten in Liste\n",
        "  list(zip(y_pred,y_test))\n",
        "  #Entzippe Liste\n",
        "  unzip_file = [{'y_pred':y_pred,'y_test':y_test}for y_pred,y_test in zip(y_pred,y_test)]\n",
        "  #Estelle DataFrame\n",
        "  data = pd.DataFrame(unzip_file)\n",
        "  #Ermittel Classification Error\n",
        "  data['class_error'] = abs(data.y_pred-data.y_test)\n",
        "  data = pd.concat([data,x_test], axis=1, join=\"inner\")\n",
        "  data['zaehler'] = 1\n",
        "\n",
        "  # Decode Features\n",
        "  data['PSP'] = label_encoder_PSP.inverse_transform(data['PSP'])\n",
        "  data['country'] = label_encoder_country.inverse_transform(data['country'])\n",
        "  data['card'] = label_encoder_card.inverse_transform(data['card'])\n",
        "  data['weekday'] = label_encoder_weekday.inverse_transform(data['weekday'])\n",
        "\n",
        "  max = data.amount.max()\n",
        "\n",
        "  def create_amount_quantiles(row):\n",
        "    if row['amount'] > 0 and row['amount'] <= max/4:\n",
        "      result = '0 - '+str(max/4)\n",
        "    else:\n",
        "      if row['amount'] > max/4 and row['amount'] <= max/4*2:\n",
        "        result = str(max/4+1)+' - '+str(max/4*2)\n",
        "      else:\n",
        "        if row['amount'] > max/4*2 and row['amount'] <= max/4*3:\n",
        "          result = str(max/4*2+1)+' - '+str(max/4*3)\n",
        "        else:\n",
        "          result = str(max/4*3+1)+' - '+str(max)\n",
        "    return result\n",
        "\n",
        "  data['amount_quantiles'] = data.apply(create_amount_quantiles, axis=1)\n",
        "\n",
        "\n",
        "  field_list = ['PSP','card','country','weekday','3D_secured','amount_quantiles']\n",
        "  error_rates = pd.DataFrame(columns=['Merkmal','Merkmalswert','class_error','zaehler'])\n",
        "\n",
        "  for field in field_list:\n",
        "    errors = data.groupby(data[field])['class_error'].sum()\n",
        "    total = data.groupby(data[field])['zaehler'].sum()\n",
        "    error_rates_tmp = pd.concat([errors, total], axis=1)\n",
        "    error_rates_tmp['Merkmalswert'] = error_rates_tmp.index.values\n",
        "    error_rates_tmp['Merkmal']=field\n",
        "    error_rates_tmp.reset_index()\n",
        "    error_rates = pd.concat([error_rates,error_rates_tmp])\n",
        "\n",
        "  error_rates['class_error_rate'] = error_rates.zaehler/error_rates.class_error\n",
        "  max_error_rate = error_rates['class_error_rate'].max()\n",
        "\n",
        "  # Visualisiere Verteilungen\n",
        "  fig = px.bar(error_rates, x='Merkmalswert', y='class_error_rate', color= 'Merkmal',labels={'class_error_rate':'Fehlerrate in %'},title=\"Verteilung der Klassifizierungsfehler\")\n",
        "  fig.add_hline(y=max_error_rate,line_dash=\"dot\",annotation_text=str(round(max_error_rate,2))+' %',annotation_position=\"top left\")\n",
        "  fig.show()\n",
        "\n",
        "#Funktionen zur Modellbewertung\n",
        "def Model_Bewertung(model,x_train, y_train,x_test, y_test,X,Y):\n",
        "  y_pred_proba = model.predict_proba(x_test)\n",
        "  cross_validation_tmp = cross_val_score(model, X, Y, cv=6)\n",
        "  cross_validation=[]\n",
        "  for value in cross_validation_tmp:\n",
        "    new = round(value,3)\n",
        "    cross_validation.append(new)\n",
        "\n",
        "  #Vorhersagen für Bewertung erzeugen\n",
        "  y_train_pred = model.predict(x_train)\n",
        "  y_test_pred = model.predict(x_test)\n",
        "\n",
        "  print('Bewertungsmetriken')\n",
        "  print('#'*20)\n",
        "  print(f\"Vorhersage-Genauigkeit auf Basis der Trainingsdaten: {round(accuracy_score(y_train, y_train_pred),2)}\")\n",
        "  print(f\"Vorhersage-Genauigkeit auf Basis der Testdaten: {round(accuracy_score(y_test, y_test_pred),2)}\")\n",
        "  print(f\"Vorhersage-Genauigkeit nach Kreuz-Validierung: {round(sum(cross_validation)/len(cross_validation),2)}\")\n",
        "  print('*'*15)\n",
        "  f1_score_train = round(f1_score(y_train_pred,y_train,zero_division=1.0,average='weighted'),2)\n",
        "  f1_score_test = round(f1_score(y_test_pred,y_test,zero_division=1.0,average='weighted'),2)\n",
        "  print(f\"F1-Score auf Basis der Trainingsdaten: {f1_score_train}\")\n",
        "  print(f\"F1-Score auf Basis der Testdaten: {f1_score_test}\")\n",
        "  print('*'*15)"
      ],
      "metadata": {
        "id": "tu0wtnR9DhaO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Bestes Modell feintunen"
      ],
      "metadata": {
        "id": "nC2o1QG23YI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import machine learning libraries\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# import packages for hyperparameters tuning\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n"
      ],
      "metadata": {
        "id": "SRqTddUfG9Js"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Merkmale reduzieren anhand Erkenntissen aus EDA --> nicht möglich, da Merkmalsgewichtung nicht einschätzbar war"
      ],
      "metadata": {
        "id": "3UWzZXHcUhRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Hyperparameter-Tuning mittels Bayesian Optimization with HYPEROPT für XGBoost Classifier\n",
        "\n",
        "Bei der Optimierung geht es darum, eine Funktion mit minimalen Kosten zu finden, die eine insgesamt bessere Leistung eines Modells sowohl im Zugsatz als auch im Testsatz bestimmt.\n",
        "In diesem Prozess trainieren wir das Modell mit verschiedenen möglichen Parameterbereichen, bis wir das am besten geeignete Modell erhalten.\n",
        "Die Optimierung von Hyperparametern hilft bei der Bestimmung der optimal abgestimmten Parameter und der Rückgabe des am besten geeigneten Modells. Dies ist die beste Vorgehensweise beim Erstellen eines ML- oder DL-Modells.\n",
        "In diesem Abschnitt besprechen wir eine der genauesten und erfolgreichsten Methoden zur Optimierung von Hyperparametern, nämlich die Bayes'sche Optimierung mit HYPEROPT.\n",
        "\n",
        "HYPEROPT ist eine leistungsstarke Python-Bibliothek, die einen Hyperparameterraum von Werten durchsucht und die bestmöglichen Werte findet, die das Minimum der Verlustfunktion ergeben. Die Bayes'sche Optimierungstechnik verwendet Hyperopt, um die Hyperparameter des Modells abzustimmen. Hyperopt ist eine Python-Bibliothek, die zur Optimierung von Modellhyperparametern verwendet wird.\n",
        "\n",
        "## Phasen\n",
        "1. Domänenraum initialisieren --> Range an Eingabewerten, die getestet werden\n"
      ],
      "metadata": {
        "id": "voOcYQnsZ7BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
        "        'gamma': hp.uniform ('gamma', 1,9),\n",
        "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
        "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
        "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
        "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
        "        'n_estimators': 180,\n",
        "        'seed': 0\n",
        "    }\n"
      ],
      "metadata": {
        "id": "z3EaSubP4wDS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die verfügbaren Hyperopt-Optimierungsalgorithmen sind:\n",
        "\n",
        "hp.choice(label, options) – Gibt eine der Optionen zurück, die eine Liste oder ein Tupel sein sollte.\n",
        "\n",
        "hp.randint(label, Upper) – Gibt eine zufällige Ganzzahl im Bereich [0, Upper) zurück.\n",
        "\n",
        "hp.uniform(label, low, high) – Gibt einen Wert zurück, der gleichmäßig zwischen niedrig und hoch liegt.\n",
        "\n",
        "hp.quniform(label, low, high, q) – Gibt einen Wert Round(uniform(low, high) / q) * q zurück, d. h. es rundet die Dezimalwerte und gibt eine ganze Zahl zurück.\n",
        "\n",
        "hp.normal(label, mean, std) – Gibt einen realen Wert zurück, der normalverteilt mit Mittelwert und Standardabweichung Sigma ist."
      ],
      "metadata": {
        "id": "pKdrGO7nGS7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. Zielfunktion definieren: Funktion, die  realen Wert zurückgibt, den es zu minimieren gilt --> Validierungsfehler in Bezug auf die Hyperparameter minimieren. Wenn der wahre Wert die Genauigkeit ist, dann wollen wir ihn maximieren. Dann sollte die Funktion das Negativ dieser Metrik zurückgeben."
      ],
      "metadata": {
        "id": "hQaV9ewXGAgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(space):\n",
        "    clf= XGBClassifier(\n",
        "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
        "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
        "                    colsample_bytree=int(space['colsample_bytree']))\n",
        "\n",
        "    evaluation = [( x_train, y_train), ( x_test, y_test)]\n",
        "\n",
        "    clf.fit(x_train, y_train,\n",
        "            eval_set=evaluation, eval_metric=\"auc\",\n",
        "            early_stopping_rounds=10,verbose=False)\n",
        "\n",
        "    pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, pred>0.79)   ##größer REferenzwert Basleine ,?? 0.79\n",
        "    print (\"SCORE:\", accuracy)\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ],
      "metadata": {
        "id": "PNaopqaQGf22"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Optimierungsalgorithmus\n",
        "Dies ist die Methode, mit der die Ersatzzielfunktion erstellt und die nächsten auszuwertenden Werte ausgewählt werden."
      ],
      "metadata": {
        "id": "Lm47v2wKGaU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trials = Trials()\n",
        "\n",
        "best_hyperparams = fmin(fn = objective,\n",
        "                        space = space,\n",
        "                        algo = tpe.suggest,\n",
        "                        max_evals = 100,\n",
        "                        trials = trials)"
      ],
      "metadata": {
        "id": "cBdhq0odHNa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Ergebnisse: Bewertungs- oder Wertepaare, die der Algorithmus zum Erstellen des Modells verwendet"
      ],
      "metadata": {
        "id": "Eck8XHmxGbFm"
      }
    }
  ]
}