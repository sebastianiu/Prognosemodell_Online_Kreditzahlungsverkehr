{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2pViSCWJZQ/WIKSZ4013s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianiu/Prognosemodell_Online_Kreditzahlungsverkehr/blob/main/models/test/model_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Daten Laden"
      ],
      "metadata": {
        "id": "3garWEz2sR9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotheken laden\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = \"https://github.com/sebastianiu/Prognosemodell_Online_Kreditzahlungsverkehr/raw/main/data/raw/PSP_Jan_Feb_2019.xlsx\"\n",
        "Datensatz = pd.read_excel(url)\n",
        "Datensatz = Datensatz.rename(columns = {\"Unnamed: 0\":\"id\"})"
      ],
      "metadata": {
        "id": "DeUdReV4UF31"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "607cnRvOUFgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Datenaufbereitung & Bewertungsfunktionen"
      ],
      "metadata": {
        "id": "005GLg72O2F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bilbiotheken laden\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "from sklearn.metrics import  precision_score,roc_curve,auc,accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay, f1_score\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def Visualisierung_AUC(model,x_test,y_test):\n",
        "  # Berechnung der Falsch-Positiv-Rate und der Wahr-Positiv-Rate fÃ¼r alle Schwellenwerte der Klassifizierung\n",
        "  probs = model.predict_proba(x_test)\n",
        "  preds = probs[:,1]\n",
        "  fpr, tpr, threshold = roc_curve(y_test, preds)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  # Visualisierung\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n",
        "\n",
        "def Visualisierung_Class_Errors(model,x_test,y_test):\n",
        "  #Vorhersage\n",
        "  y_pred = model.predict(x_test)\n",
        "  #Zippe Daten in Liste\n",
        "  list(zip(y_pred,y_test))\n",
        "  #Entzippe Liste\n",
        "  unzip_file = [{'y_pred':y_pred,'y_test':y_test}for y_pred,y_test in zip(y_pred,y_test)]\n",
        "  #Estelle DataFrame\n",
        "  data = pd.DataFrame(unzip_file)\n",
        "  #Ermittel Classification Error\n",
        "  data['class_error'] = abs(data.y_pred-data.y_test)\n",
        "  data = pd.concat([data,x_test], axis=1, join=\"inner\")\n",
        "  data['zaehler'] = 1\n",
        "\n",
        "  # Decode Features\n",
        "  data['PSP'] = label_encoder_PSP.inverse_transform(data['PSP'])\n",
        "  data['country'] = label_encoder_country.inverse_transform(data['country'])\n",
        "  data['card'] = label_encoder_card.inverse_transform(data['card'])\n",
        "  data['weekday'] = label_encoder_weekday.inverse_transform(data['weekday'])\n",
        "\n",
        "  max = data.amount.max()\n",
        "\n",
        "  def create_amount_quantiles(row):\n",
        "    if row['amount'] > 0 and row['amount'] <= max/4:\n",
        "      result = '0 - '+str(max/4)\n",
        "    else:\n",
        "      if row['amount'] > max/4 and row['amount'] <= max/4*2:\n",
        "        result = str(max/4+1)+' - '+str(max/4*2)\n",
        "      else:\n",
        "        if row['amount'] > max/4*2 and row['amount'] <= max/4*3:\n",
        "          result = str(max/4*2+1)+' - '+str(max/4*3)\n",
        "        else:\n",
        "          result = str(max/4*3+1)+' - '+str(max)\n",
        "    return result\n",
        "\n",
        "  data['amount_quantiles'] = data.apply(create_amount_quantiles, axis=1)\n",
        "\n",
        "\n",
        "  field_list = ['PSP','card','country','weekday','3D_secured','amount_quantiles']\n",
        "  error_rates = pd.DataFrame(columns=['Merkmal','Merkmalswert','class_error','zaehler'])\n",
        "\n",
        "  for field in field_list:\n",
        "    errors = data.groupby(data[field])['class_error'].sum()\n",
        "    total = data.groupby(data[field])['zaehler'].sum()\n",
        "    error_rates_tmp = pd.concat([errors, total], axis=1)\n",
        "    error_rates_tmp['Merkmalswert'] = error_rates_tmp.index.values\n",
        "    error_rates_tmp['Merkmal']=field\n",
        "    error_rates_tmp.reset_index()\n",
        "    error_rates = pd.concat([error_rates,error_rates_tmp])\n",
        "\n",
        "  error_rates['class_error_rate'] = error_rates.zaehler/error_rates.class_error\n",
        "  max_error_rate = error_rates['class_error_rate'].max()\n",
        "\n",
        "  # Visualisiere Verteilungen\n",
        "  fig = px.bar(error_rates, x='Merkmalswert', y='class_error_rate', color= 'Merkmal',labels={'class_error_rate':'Klassifizierungsfehler in %'},title=\"Fehlerrate Klassifizierungen\")\n",
        "  fig.add_hline(y=max_error_rate,line_dash=\"dot\",annotation_text=str(round(max_error_rate,2))+' %',annotation_position=\"top left\")\n",
        "  fig.show()\n",
        "\n",
        "def Model_Bewertung(model,x_train, y_train,x_test, y_test,X,Y):\n",
        "  y_pred_proba = model.predict_proba(x_test)\n",
        "  cross_validation_tmp = cross_val_score(model, X, Y, cv=6)\n",
        "  cross_validation=[]\n",
        "  for value in cross_validation_tmp:\n",
        "    new = round(value,3)\n",
        "    cross_validation.append(new)\n",
        "\n",
        "\n",
        "  print('Bewertungsmetriken')\n",
        "  print('#'*20)\n",
        "  print(f\"Vorhersage-Genauigkeit auf Basis der Trainingsdaten: {round(model.score(x_train, y_train),2)}\")\n",
        "  print(f\"Vorhersage-Genauigkeit auf Basis der Testdaten: {round(model.score(x_test, y_test),2)}\")\n",
        "  print('*'*15)\n",
        "  precision_train = round(precision_score(y_train,model.predict(x_train),zero_division=1.0,average='weighted'),2)\n",
        "  precision_test = round(precision_score(y_test,model.predict(x_test),zero_division=1.0,average='weighted'),2)\n",
        "  print(f\"Precision auf Basis der Trainingsdaten: {precision_train}\")\n",
        "  print(f\"Precision auf Basis der Testdaten: {precision_test}\")\n",
        "  print('*'*15)\n",
        "  f1_score_train = round(f1_score(y_train,model.predict(x_train),zero_division=1.0,average='weighted'),2)\n",
        "  f1_score_test = round(f1_score(y_test,model.predict(x_test),zero_division=1.0,average='weighted'),2)\n",
        "  print(f\"F1-Score auf Basis der Trainingsdaten: {f1_score_train}\")\n",
        "  print(f\"F1-Score auf Basis der Testdaten: {f1_score_test}\")\n",
        "  print('*'*15)\n",
        "  print(f\"Vorhersage-Genauigkeiten nach Kreuz-Validierung: {cross_validation}\")\n",
        "  print(f\"Durschn. Vorhersage-Genauigkeit nach Kreuz-Validierung: {round(sum(cross_validation)/len(cross_validation),3)}\")\n",
        "\n",
        "  print('*'*15)\n",
        "\n",
        "# Datenaufbereitung\n",
        "label_encoder_PSP = LabelEncoder()\n",
        "label_encoder_country = LabelEncoder()\n",
        "label_encoder_card = LabelEncoder()\n",
        "label_encoder_weekday = LabelEncoder()\n",
        "\n",
        "ML_Daten = Datensatz.filter(['amount','success','PSP','country','card','tmsp','3D_secured'], axis=1)\n",
        "\n",
        "ML_Daten['country'] = label_encoder_country.fit_transform(ML_Daten['country'])\n",
        "ML_Daten['PSP'] = label_encoder_PSP.fit_transform(ML_Daten['PSP'])\n",
        "ML_Daten['card'] = label_encoder_card.fit_transform(ML_Daten['card'])\n",
        "\n",
        "# Datumswerte in Tag/ Wochentag/ Stunde aufteilen\n",
        "ML_Daten['weekday'] = ML_Daten['tmsp'].dt.day_name()\n",
        "ML_Daten['weekday'] = label_encoder_weekday.fit_transform(ML_Daten['weekday'])\n",
        "ML_Daten['day'] = ML_Daten['tmsp'].dt.strftime('%d').astype(int)\n",
        "ML_Daten['hour'] = ML_Daten['tmsp'].dt.strftime('%H').astype(int)\n",
        "\n",
        "# Separation in X Merkmale and Zielvariable Y\n",
        "Y = ML_Daten['success']\n",
        "X = ML_Daten.filter(['amount','PSP','3D_secured','card','country','weekday','day','hour'], axis=1)\n",
        "\n",
        "# Aufteilung in Trainings- und Validierungsdatensatz\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "X1il56daO1EW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Bestes Modell feintunen"
      ],
      "metadata": {
        "id": "nC2o1QG23YI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Merkmale reduzieren anhand Erkenntissen aus EDA und Separation in X Merkmale and Zielvariable Y"
      ],
      "metadata": {
        "id": "3UWzZXHcUhRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = ML_Daten.filter(['amount','PSP','3D_secured'], axis=1)\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, Y, test_size=0.2)"
      ],
      "metadata": {
        "id": "tK6HtvKi3koZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Hyperparameter-Tuning mittels Kreuz-Validierung\n",
        "#### 3.1 Random Forest Classifier\n",
        "##### Hyperparameter-Raster"
      ],
      "metadata": {
        "id": "voOcYQnsZ7BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Hyper-Parameter fÃ¼r Raster\n",
        "# Anzahl an BÃ¤umen im RandomForest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n",
        "# Azahl der betrachteten Merkmale fÃ¼r jede Aufteilung\n",
        "max_features = ['auto','sqrt']\n",
        "# Maximale Anzahl an Ebenen in einem Baum\n",
        "max_depth = [2,4]\n",
        "# Minimale Anzahl der Proben, die zum Teilen eines Knotens erforderlich sind\n",
        "min_samples_split = [2,5]\n",
        "# Minimale Anzahl der Proben, die fÃ¼r jeden Knoten erforderlich sind\n",
        "min_samples_leaf = [1,2]\n",
        "#Bootstrap-Method zur Zusammenstellung der Trainingsdaten fÃ¼r jeden Baum verwenden - Ja/ Nein\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Erzeugen eines zufÃ¤lligen Parameter-Rasters\n",
        "param_grid= {'n_estimators': n_estimators,\n",
        "            'max_features': max_features,\n",
        "            'max_depth': max_depth,\n",
        "            'min_samples_split': min_samples_split,\n",
        "            'min_samples_leaf': min_samples_leaf,\n",
        "            'bootstrap': bootstrap}"
      ],
      "metadata": {
        "id": "z3EaSubP4wDS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Umfassende Rastersuche"
      ],
      "metadata": {
        "id": "LJJG1iytqHR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_final = RandomForestClassifier()\n",
        "#rfc_final.fit(X2,Y)\n",
        "\n",
        "rf_Gridsearch = GridSearchCV(estimator = rfc_final, param_grid = param_grid, cv = 3, verbose=2, n_jobs = 4)\n",
        "rf_Gridsearch.fit(x_train2,y_train2)\n",
        "\n",
        "print('Optimale H-Parameter')\n",
        "print('+'*20)\n",
        "print(rf_Gridsearch.best_params_)\n",
        "\n",
        "#Bewertung der ermittelten optimalen HP\n",
        "print('Model-Bewertung mit Hyper-Parametern ermittelt mit GridSearchCV')\n",
        "print(f'Vorhersage-Genauigkeit auf Basis der Trainingsdaten: {rf_Gridsearch.score(x_train2,y_train2):.3f}')\n",
        "print(f'Vorhersage-Genauigkeit auf Basis der Testdaten: {rf_Gridsearch.score(x_test2,y_test2):.3f}')"
      ],
      "metadata": {
        "id": "SH6sI0cfp9XY",
        "outputId": "ca769c37-3db7-47b9-c506-0267c9450576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n",
            "Optimale H-Parameter\n",
            "++++++++++++++++++++\n",
            "{'bootstrap': True, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 33}\n",
            "Model-Bewertung mit Hyper-Parametern ermittelt mit GridSearchCV\n",
            "Vorhersage-Genauigkeit auf Basis der Trainingsdaten: 0.801\n",
            "Vorhersage-Genauigkeit auf Basis der Testdaten: 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Zufalls-basierte Parameter-Optimierung"
      ],
      "metadata": {
        "id": "kkobUIBdaZ65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "rf_GridsearchRandom = RandomizedSearchCV(estimator = rfc_final, param_distributions = param_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "optimized_HParams = rf_GridsearchRandom.fit(x_train2,y_train2)\n",
        "\n",
        "print('Optimale H-Parameter')\n",
        "print('+'*20)\n",
        "print(rf_GridsearchRandom.best_params_)\n",
        "\n",
        "#Bewertung der ermittelten optimalen HP\n",
        "print('Model-Bewertung mit Hyper-Parametern ermittelt mit RandomizedSearchCV')\n",
        "print(f'Vorhersage-Genauigkeit auf Basis der Trainingsdaten: {rf_GridsearchRandom.score(x_train2,y_train2):.3f}')\n",
        "print(f'Vorhersage-Genauigkeit auf Basis der Testdaten: {rf_GridsearchRandom.score(x_test2,y_test2):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "gq-n8qQ_t4XV",
        "outputId": "112a8259-994a-4fa1-83bb-9e12df3fea3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning:\n",
            "\n",
            "`max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimale H-Parameter\n",
            "++++++++++++++++++++\n",
            "{'n_estimators': 41, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 4, 'bootstrap': True}\n",
            "Model-Bewertung mit Hyper-Parametern ermittelt mit RandomizedSearchCV\n",
            "Vorhersage-Genauigkeit auf Basis der Trainingsdaten: 0.802\n",
            "Vorhersage-Genauigkeit auf Basis der Testdaten: 0.793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regularisierung"
      ],
      "metadata": {
        "id": "yTU6CaysU5Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finales Training mit allen Daten"
      ],
      "metadata": {
        "id": "8Ijo4JhrU8-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_tmp = rf_Gridsearch.best_params_\n",
        "param_grid = pd.DataFrame(param_grid_tmp,index=[0])\n",
        "\n",
        "rfc_final = RandomForestClassifier(\n",
        "    bootstrap = param_grid.bootstrap.iloc[0]\n",
        "    ,max_depth = param_grid.max_depth.iloc[0]\n",
        "    ,max_features = param_grid.max_features.iloc[0]\n",
        "    ,min_samples_leaf = param_grid.min_samples_leaf.iloc[0]\n",
        "    ,min_samples_split = param_grid.min_samples_split.iloc[0]\n",
        "    ,n_estimators = param_grid.n_estimators.iloc[0]\n",
        ")\n",
        "\n",
        "rfc_final.fit(X2,Y)\n",
        "\n",
        "#Finale Bewertung\n",
        "Model_Bewertung(rfc_final,x_train2, y_train2,x_test2, y_test2,X,Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPrES6vbVbEx",
        "outputId": "4faca071-5360-4f7a-ffa6-85dcc15f62c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bewertungsmetriken\n",
            "####################\n",
            "Vorhersage-Genauigkeit auf Basis der Trainingsdaten: 0.8\n",
            "Vorhersage-Genauigkeit auf Basis der Testdaten: 0.8\n",
            "***************\n",
            "Precision auf Basis der Trainingsdaten: 0.76\n",
            "Precision auf Basis der Testdaten: 0.76\n",
            "***************\n",
            "F1-Score auf Basis der Trainingsdaten: 0.72\n",
            "F1-Score auf Basis der Testdaten: 0.72\n",
            "***************\n",
            "Vorhersage-Genauigkeiten nach Kreuz-Validierung: [0.797, 0.797, 0.797, 0.797, 0.797, 0.797]\n",
            "Durschn. Vorhersage-Genauigkeit nach Kreuz-Validierung: 0.797\n",
            "***************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KFbHd-k7VG5V"
      }
    }
  ]
}